Задача в том, чтобы найти k наиболее часто встречающихся слов в данном списке слов. Если два слова имеют одинаковую частоту, то слово с более меньшим лексикографическим порядком должно быть предпочтительнее.

Constraints: 1 <= words.length <= 500

Для решения этой задачи мы можем использовать хэш-таблицу для подсчёта частоты каждого слова в списке. Затем мы можем использовать кучу (heap) для хранения k наиболее часто встречающихся слов. Куча будет хранить пары (слово, частота), и мы будем сравнивать пары по частоте, а если частоты равны, то по лексикографическому порядку слов.

```go
package main

import (
	"container/heap"
	"fmt"
	"strings"
)

type WordFreq struct {
  Word string
  Freq int
}

type WordHeap []WordFreq

func NewWordHeap(capacity int) *WordHeap {
  h := make(WordHeap, 0, capacity)
  return &h
}

func (h WordHeap) Len() int {
  return len(h)
}

func (h WordHeap) Less(a, b int) bool {
  return h[a].Freq < h[b].Freq ||
    h[a].Freq == h[b].Freq && strings.Compare(h[a].Word, h[b].Word) > 0
}

func (h WordHeap) Swap(a, b int) {
  h[a], h[b] = h[b], h[a]
}

func (h *WordHeap) Push(x any) {
  *h = append(*h, x.(WordFreq))
}

func (h *WordHeap) Pop() any {
  old := *h
  ln := len(old)
  x := old[ln-1]
  *h = old[:ln-1]
  return x
}

func topKFrequent(words []string, k int) []string {
  freqMap := make(map[string]int)
  for _, word := range words {
    freqMap[word]++
  }
  h := NewWordHeap(k + 1)
  for word, freq := range freqMap {
    heap.Push(h, WordFreq{word, freq})
    if h.Len() > k {
      heap.Pop(h)
    }
  }
  ln := h.Len()
  result := make([]string, ln)
  for i := ln - 1; i >= 0; i-- {
    result[i] = heap.Pop(h).(WordFreq).Word  // !! нельзя извлекать через (*h)[ln-i-1].Word
  }
  return result
}

func main() {
	var words []string
	// Input: words = ["i","love","leetcode","i","love","coding"], k = 2
	// Output: ["i","love"]
	// Explanation: "i" and "love" are the two most frequent words.
	// Note that "i" comes before "love" due to a lower alphabetical order.
	words = []string{"i", "love", "leetcode", "i", "love", "coding"}
	fmt.Printf("%v\n", topKFrequent(words, 2))
	// Input: words = ["the","day","is","sunny","the","the","the","sunny","is","is"], k = 4
	// Output: ["the","is","sunny","day"]
	// Explanation: "the", "is", "sunny" and "day" are the four most frequent words, with the number of occurrence being 4, 3, 2 and 1 respectively.
	words = []string{"the", "day", "is", "sunny", "the", "the", "the", "sunny", "is", "is"}
	fmt.Printf("%v\n", topKFrequent(words, 4))
}
```

В этом коде мы определяем тип `WordFreq`, который представляет слово и его частоту. Затем мы определяем тип `WordHeap`, который представляет кучу слов и их частот. Мы реализуем необходимые методы для этого типа, включая методы `Push` и `Pop`, которые используются для добавления и удаления элементов из кучи. При этом метод `Less` для кучи максимумов.

Затем мы создаём хэш-таблицу `freqMap`, чтобы подсчитать частоту каждого слова в списке. Затем создаем пустую кучу `h` и инициализируем её. Затем мы проходим по хэш-таблице и добавляем каждое слово и его частоту в кучу. Если размер кучи превышает `k`, то удаляем наименьший элемент из кучи.

Наконец, мы создаём массив `result` размера `k`, и заполняем его `k` наиболее часто встречающимися словами из кучи. Мы делаем это, извлекая элементы из кучи и сохраняя слова в массиве `result`.

Алгоритмическая сложность функции `topKFrequent()` в худшем случае равна `O(n log k)`, где `n` - количество слов в массиве `words`, `k` - количество уникальных слов, которые нужно вернуть.

---

Вариант реализациии через sort.Slice()

Вот шаги алгоритма:

- Создать пустой словарь `freqMap`, где ключ - это слово, а значение - это количество его вхождений в массив `words`.
- Обойти массив `words`, увеличивая значение частоты для каждого слова в словаре `freqMap`.
- Создать пустой массив `freqSlice` типа `WordFreq` (структура, которая включает в себя слово и его частоту вхождения), и заполнить его элементами, полученными из словаря `freqMap`.
- Отсортировать массив `freqSlice` по убыванию частоты и лексикографического порядка слов.
- Создать пустой массив `result` и вставить в него первые `k` слов из отсортированного массива `freqSlice`.

```go
package main

import (
	"fmt"
	"sort"
	"strings"
)

type WordFreq struct {
	word string
	freq int
}

func topKFrequent(words []string, k int) []string {
	freqMap := make(map[string]int)
	for _, word := range words {
		freqMap[word]++
	}
	freqSlice := make([]WordFreq, 0, len(freqMap))
	for word, freq := range freqMap {
		freqSlice = append(freqSlice, WordFreq{word, freq})
	}
	sort.Slice(freqSlice, func(i, j int) bool {
		return freqSlice[i].freq > freqSlice[j].freq ||
			(freqSlice[i].freq == freqSlice[j].freq && strings.Compare(freqSlice[i].word, freqSlice[j].word) < 0)
	})
	result := make([]string, 0, k)
	for _, wordFreq := range freqSlice[:k] {
		result = append(result, wordFreq.word)
	}
	return result
}

func main() {
	var words []string
	// Input: words = ["i","love","leetcode","i","love","coding"], k = 2
	// Output: ["i","love"]
	// Explanation: "i" and "love" are the two most frequent words.
	// Note that "i" comes before "love" due to a lower alphabetical order.
	words = []string{"i", "love", "leetcode", "i", "love", "coding"}
	fmt.Printf("%v\n", topKFrequent(words, 2))
	// Input: words = ["the","day","is","sunny","the","the","the","sunny","is","is"], k = 4
	// Output: ["the","is","sunny","day"]
	// Explanation: "the", "is", "sunny" and "day" are the four most frequent words, with the number of occurrence being 4, 3, 2 and 1 respectively.
	words = []string{"the", "day", "is", "sunny", "the", "the", "the", "sunny", "is", "is"}
	fmt.Printf("%v\n", topKFrequent(words, 4))
}
```

Алгоритмическая сложность функции `topKFrequent()` в этом примере - `O(n log n)`, где `n` - количество слов в массиве `words`. Это связано с использованием сортировки в функции. Ещё один цикл `for` проходит по `k` элементов отсортированного массива `freqSlice`. Это добавляет `O(k)` к сложности, но, так как `k` меньше, чем `n`, то общая сложность по-прежнему будет `O(n log n)`.
